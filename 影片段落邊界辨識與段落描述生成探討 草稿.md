摘要

近期線上課程與網路影片興盛，大學端也養成了課程錄影的習慣，但大部分的課程錄影不會做太多的剪輯，一段錄影至少30分鐘起跳，未經整理的影片十分攏長且難以理解，於是本研究提出一套流程，透過影片字幕檔STR，和BERT預訓練時學習的NSP(Next Sentence Prediction)任務，自動選擇影片段落的切分點，並對切分的段落產生一段摘要，我們測試了需多方法去生成摘要，主要分兩類，抽取式和抽象式，抽取式主要從輸入文本中選擇重要的內容將其輸出，可以將其視為一種分類問題(重要OR不重要)，抽象式摘要則是根據輸入文本的內容生成出一段相較簡短但意義近似的文本，可以將其視為一種風格轉移(攏長的transfer簡短的)，最後我們分別選擇了A和B作為我們的摘要模型。

關鍵字：影片段落邊界辨識、影片段落摘要、BERT

1.研究動機與目的

最近影音平台如YT等等，提供TIMECODE功能，讓閱聽人可以快速跳到段落主題的開頭，使閱聽人可快速瀏覽影片的整體架構，達到快速理解快速吸收的效果，而TIMECODE目前多使上傳者對其手動標記，但影片的長度一長，如課程錄影、立法院會期紀錄這種壟長且沒有腳本或大綱的影片，人工標註的方法會需要對影片有足夠的了解並對其逕行整理，這個過程十分的耗時，於是我們想要研究可以有效辨別影片段落邊界和生成影片段落摘要的方法。

本研究的首要目標為運用自然語言處理（NLP,Natural language processing）技術、推論統計技巧及機器學習模型，嘗試自動切割影片段落並對段落內容製作摘要與整理。

2.相關研究與文獻探討

bert transformer 餘弦相似性（paper）

2.1影片段落邊界

2.2影片段落摘要

3.研究流程

3.1 實驗流程

一個影片的內容存在於畫面與聲音之中，從聲音之中我們可以透過ASR（語音辨識）技術將聲音轉換為文字資料也就是字幕，於是我們使用自動字幕產生軟體取得影片的字幕檔。
